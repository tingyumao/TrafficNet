{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from ssd.ssd import SSD\n",
    "from ssd.ssd_loss import MultiboxLoss\n",
    "from ssd.ssd_bbox import BBoxUtility\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants\n",
    "NUM_CLASSES = 4 # remember the background \n",
    "input_shape = (300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 7308, 8)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "## priorbox defined by ourselves\n",
    "prior_tensor = tf.ones((1, 300, 300, 3))\n",
    "ssd_net = SSD(input_shape, NUM_CLASSES)\n",
    "_, priors = ssd_net(prior_tensor, PRIORS = True)\n",
    "print(priors.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ng = tf.Graph()\\nwith g.as_default():\\n    #a = tf.placeholder(tf.float32, name=\"a\")\\n    #b = tf.placeholder(tf.float32, name=\"b\")\\n    #c = a + b\\n    ## priorbox defined by ourselves\\n    prior_tensor = tf.ones((1, 300, 300, 3))\\n    ssd_net = SSD(input_shape, NUM_CLASSES)\\n    _, priors = ssd_net(prior_tensor, PRIORS = True)\\n    print(priors.shape)\\n    \\ntf.summary.FileWriter(\"logs\", g).close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG by tensorboard\n",
    "\"\"\"\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    #a = tf.placeholder(tf.float32, name=\"a\")\n",
    "    #b = tf.placeholder(tf.float32, name=\"b\")\n",
    "    #c = a + b\n",
    "    ## priorbox defined by ourselves\n",
    "    prior_tensor = tf.ones((1, 300, 300, 3))\n",
    "    ssd_net = SSD(input_shape, NUM_CLASSES)\n",
    "    _, priors = ssd_net(prior_tensor, PRIORS = True)\n",
    "    print(priors.shape)\n",
    "    \n",
    "tf.summary.FileWriter(\"logs\", g).close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save priors tensor\n",
    "#with open('./data/priors300.pkl', 'wb') as handle:\n",
    "#    pickle.dump(priors_np, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7308, 8)\n"
     ]
    }
   ],
   "source": [
    "# load priors tensor\n",
    "with open('./data/priors300.pkl', 'rb') as handle:\n",
    "    priors_np = pickle.load(handle)\n",
    "    print(priors_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#priors_np = np.squeeze(sess.run(priors))\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 7308, 8]\n"
     ]
    }
   ],
   "source": [
    "print([None,] + list(priors_np.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "## bounding box ground truth\n",
    "gt = pickle.load(open('./data/indata.pkl', 'rb'))\n",
    "keys = sorted(gt.keys())\n",
    "random.shuffle(keys)\n",
    "num_train = int(round(0.8 * len(keys)))\n",
    "train_keys = keys[:num_train]\n",
    "val_keys = keys[num_train:]\n",
    "num_val = len(val_keys)\n",
    "print(num_train)\n",
    "print(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ssd.preprocess import *\n",
    "## input images\n",
    "## define input data generator: return a batch of input images as well as target feature vectors \n",
    "## like 64587, 8+num_classes\n",
    "path_prefix = './data/train/'\n",
    "\n",
    "# batch_size = 4\n",
    "gen = Generator(gt, bbox_util, 4, './data/train/',\n",
    "                train_keys, val_keys,\n",
    "                (input_shape[0], input_shape[1]), do_crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tingyumao/Programs/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "input_ph = tf.placeholder(tf.float32, [None,] + list(input_shape), name=\"input_image\")\n",
    "gt_ph = tf.placeholder(tf.float32, [None, 7308, 16], name=\"ground_truth\")\n",
    "with tf.variable_scope(\"ssd_net\"):\n",
    "    ssd_net = SSD(input_shape, NUM_CLASSES)\n",
    "    predictions = ssd_net(input_ph, PRIORS = False)\n",
    "    \n",
    "with tf.variable_scope(\"loss\"):\n",
    "    loss = MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss(gt_ph, predictions)\n",
    "    \n",
    "with tf.variable_scope(\"train\"):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    lr = tf.train.exponential_decay(3e-4, global_step, num_train//batch_size, 0.9, staircase=True, name=\"lr\")\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4/333, minibatch loss: [ 6.46188307  5.89722157  6.77153778  5.8900547 ]\n",
      "training 8/333, minibatch loss: [ 18.93037033  16.27460098  24.52888489  17.32169914]\n",
      "training 12/333, minibatch loss: [  9.07914543   8.41857529  10.43834972   9.04242897]\n",
      "training 16/333, minibatch loss: [ 4.99908066  4.07078409  5.23704863  5.61124802]\n",
      "training 20/333, minibatch loss: [ 5.92088461  5.40038872  7.35792685  6.34349632]\n",
      "training 24/333, minibatch loss: [ 5.9510498   5.00807667  5.46769619  4.48874092]\n",
      "training 28/333, minibatch loss: [ 3.90168166  3.9039278   3.96347284  3.61905575]\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 20\n",
    "train_loss_hist = []\n",
    "\n",
    "train_generator = gen.generate(True)\n",
    "val_generator = gen.generate(False)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(nb_epoch):\n",
    "    # training phase\n",
    "    cnt = 0\n",
    "    for sample in train_generator:\n",
    "        _, train_input, train_target = sample\n",
    "        train_loss, _ = sess.run([loss, train_op], feed_dict={input_ph: train_input, gt_ph: train_target})\n",
    "        train_loss_hist.append(train_loss)\n",
    "        cnt += 1\n",
    "        print(\"training {}/{}, minibatch loss: {}\".format(cnt*batch_size, num_train, train_loss))\n",
    "        if cnt > (num_train//batch_size+1):\n",
    "            cnt = 0\n",
    "            break\n",
    "        \n",
    "    # validation phase\n",
    "    val_loss = 0.0\n",
    "    for sample in val_generator:\n",
    "        _, val_input, val_target = sample\n",
    "        val_loss += sess.run(loss, feed_dict={input_ph: val_input, gt_ph: val_target})\n",
    "        if cnt > (num_val//batch_size+1):\n",
    "            cnt = 0\n",
    "            break\n",
    "    \n",
    "    # print progress\n",
    "    verbose_loss = np.mean(train_loss_hist[-(num_train//batch_size+1):])\n",
    "    print(\"epoch {}/{}, train loss: {}, val loss: {}\".format(e, nb_epoch, verbose_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Generator.generate at 0x1419b9728>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.generate(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
